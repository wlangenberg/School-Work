{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea408ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a568a20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We start by reading the data\n",
    "df = pd.read_csv('../Data/data.txt', names = ['x','y'])\n",
    "\n",
    "# Plotting the data\n",
    "df.plot(x='x', y='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "095876d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b05084b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.fc = nn.Linear(1,1)\n",
    "        self.relu = torch.nn.ReLU() # instead of Heaviside step fn\n",
    "    def forward(self, x):\n",
    "        output = self.fc(x)\n",
    "        output = self.relu(x) # instead of Heaviside step fn\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9c4accbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward(torch.nn.Module):\n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(Feedforward, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "            self.fc3 = torch.nn.Linear(self.hidden_size, 1)\n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.sigmoid = torch.nn.Sigmoid()\n",
    "            \n",
    "        def forward(self, x):\n",
    "            input_layer = self.fc1(x)\n",
    "            hidden1 = self.relu(input_layer)\n",
    "            hidden2 = self.fc2(hidden1)\n",
    "            hidden22 = self.relu(hidden2)\n",
    "            output = self.fc3(hidden22)\n",
    "            output = self.sigmoid(output)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c5a61191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into 90/10 train/test datasets.\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.x, df.y, test_size=0.20, random_state=99)\n",
    "df_train, df_test = train_test_split(df, test_size=0.20, random_state=99)\n",
    "\n",
    "X_train = torch.FloatTensor(x_train.values).reshape((160,1))\n",
    "X_test = torch.FloatTensor(x_test.values).reshape((40,1))\n",
    "Y_train = torch.FloatTensor(y_train.values).reshape((160,1))\n",
    "Y_test = torch.FloatTensor(y_test.values).reshape((40,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1f3eabb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Feedforward(1, 50)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "89b3cab1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 102.753662109375 val loss: 82.40882110595703\n",
      "Epoch 1: train loss: 102.753662109375 val loss: 82.40830993652344\n",
      "Epoch 2: train loss: 102.753662109375 val loss: 82.4078598022461\n",
      "Epoch 3: train loss: 102.753662109375 val loss: 82.40743255615234\n",
      "Epoch 4: train loss: 102.753662109375 val loss: 82.40704345703125\n",
      "Epoch 5: train loss: 102.753662109375 val loss: 82.40664672851562\n",
      "Epoch 6: train loss: 102.753662109375 val loss: 82.40631866455078\n",
      "Epoch 7: train loss: 102.7536392211914 val loss: 82.40597534179688\n",
      "Epoch 8: train loss: 102.7536392211914 val loss: 82.40567016601562\n",
      "Epoch 9: train loss: 102.753662109375 val loss: 82.40538024902344\n",
      "Epoch 10: train loss: 102.7536392211914 val loss: 82.40510559082031\n",
      "Epoch 11: train loss: 102.753662109375 val loss: 82.40484619140625\n",
      "Epoch 12: train loss: 102.753662109375 val loss: 82.40460205078125\n",
      "Epoch 13: train loss: 102.7536392211914 val loss: 82.40437316894531\n",
      "Epoch 14: train loss: 102.753662109375 val loss: 82.4041519165039\n",
      "Epoch 15: train loss: 102.7536392211914 val loss: 82.40397644042969\n",
      "Epoch 16: train loss: 102.7536392211914 val loss: 82.40377807617188\n",
      "Epoch 17: train loss: 102.753662109375 val loss: 82.40360260009766\n",
      "Epoch 18: train loss: 102.7536392211914 val loss: 82.40343475341797\n",
      "Epoch 19: train loss: 102.753662109375 val loss: 82.40328979492188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willielangenberg/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([160, 1])) that is different to the input size (torch.Size([160])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/willielangenberg/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([40, 1])) that is different to the input size (torch.Size([40])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "epoch = 20\n",
    "for epoch in range(epoch):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model(X_train)\n",
    "    # Compute Loss\n",
    "    loss = criterion(y_pred.squeeze(), Y_train)\n",
    "    \n",
    "    validation_loss = criterion(model(X_test).squeeze(), Y_test).item()\n",
    "    \n",
    "    print(f'Epoch {epoch}: train loss: {loss.item()} val loss: {validation_loss}')\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2c489e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss after Training 81.38797760009766\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred = model(X_test)\n",
    "validation_loss = criterion(model(X_test).squeeze(), Y_test).item()\n",
    "print('Test loss after Training' , after_train.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1f70f9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.75</td>\n",
       "      <td>2.701526</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.35</td>\n",
       "      <td>2.073915</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.55</td>\n",
       "      <td>-21.165762</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.70</td>\n",
       "      <td>-2.646876</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1.286706</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.627001</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.95</td>\n",
       "      <td>-1.286706</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-3.20</td>\n",
       "      <td>3.792295</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.30</td>\n",
       "      <td>1.976162</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.35</td>\n",
       "      <td>-19.235647</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.932188</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-2.55</td>\n",
       "      <td>-1.509702</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.75</td>\n",
       "      <td>0.344480</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.05</td>\n",
       "      <td>1.478784</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-2.50</td>\n",
       "      <td>-1.737592</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.75</td>\n",
       "      <td>-22.367933</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-3.80</td>\n",
       "      <td>11.840905</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-2.85</td>\n",
       "      <td>0.394653</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-4.55</td>\n",
       "      <td>21.165762</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.65</td>\n",
       "      <td>0.978642</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-2.80</td>\n",
       "      <td>0.011915</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-2.70</td>\n",
       "      <td>-0.674605</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.151678</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-2.35</td>\n",
       "      <td>-2.277736</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.95</td>\n",
       "      <td>-1.238868</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.75</td>\n",
       "      <td>-2.701526</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.95</td>\n",
       "      <td>-14.011615</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-3.00</td>\n",
       "      <td>1.699897</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.430731</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.627001</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2.20</td>\n",
       "      <td>2.618420</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.100499</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-4.30</td>\n",
       "      <td>18.663345</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.70</td>\n",
       "      <td>-0.851056</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.25</td>\n",
       "      <td>2.525605</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3.55</td>\n",
       "      <td>-8.263088</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-1.85</td>\n",
       "      <td>-2.780123</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.70</td>\n",
       "      <td>-22.146532</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3.70</td>\n",
       "      <td>-10.391427</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-1.40</td>\n",
       "      <td>-2.169436</td>\n",
       "      <td>0.550372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x          y    y_pred\n",
       "0   1.75   2.701526  0.550372\n",
       "1   1.35   2.073915  0.550372\n",
       "2   4.55 -21.165762  0.550372\n",
       "3  -1.70  -2.646876  0.550372\n",
       "4   0.95   1.286706  0.550372\n",
       "5   0.55   0.627001  0.550372\n",
       "6  -0.95  -1.286706  0.550372\n",
       "7  -3.20   3.792295  0.550372\n",
       "8   1.30   1.976162  0.550372\n",
       "9   4.35 -19.235647  0.550372\n",
       "10 -0.75  -0.932188  0.550372\n",
       "11 -2.55  -1.509702  0.550372\n",
       "12  2.75   0.344480  0.550372\n",
       "13  1.05   1.478784  0.550372\n",
       "14 -2.50  -1.737592  0.550372\n",
       "15  4.75 -22.367933  0.550372\n",
       "16 -3.80  11.840905  0.550372\n",
       "17 -2.85   0.394653  0.550372\n",
       "18 -4.55  21.165762  0.550372\n",
       "19  2.65   0.978642  0.550372\n",
       "20 -2.80   0.011915  0.550372\n",
       "21 -2.70  -0.674605  0.550372\n",
       "22  0.15   0.151678  0.550372\n",
       "23 -2.35  -2.277736  0.550372\n",
       "24  2.95  -1.238868  0.550372\n",
       "25 -1.75  -2.701526  0.550372\n",
       "26  3.95 -14.011615  0.550372\n",
       "27 -3.00   1.699897  0.550372\n",
       "28 -0.40  -0.430731  0.550372\n",
       "29 -0.55  -0.627001  0.550372\n",
       "30  2.20   2.618420  0.550372\n",
       "31 -0.10  -0.100499  0.550372\n",
       "32 -4.30  18.663345  0.550372\n",
       "33 -0.70  -0.851056  0.550372\n",
       "34  2.25   2.525605  0.550372\n",
       "35  3.55  -8.263088  0.550372\n",
       "36 -1.85  -2.780123  0.550372\n",
       "37  4.70 -22.146532  0.550372\n",
       "38  3.70 -10.391427  0.550372\n",
       "39 -1.40  -2.169436  0.550372"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'x': X_test.detach().numpy().flatten(), 'y' : Y_test.detach().numpy().flatten(), 'y_pred' : y_pred.detach().numpy().flatten()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eb77e409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.7500,  1.3500,  4.5500, -1.7000,  0.9500,  0.5500, -0.9500, -3.2000,\n",
       "         1.3000,  4.3500, -0.7500, -2.5500,  2.7500,  1.0500, -2.5000,  4.7500,\n",
       "        -3.8000, -2.8500, -4.5500,  2.6500, -2.8000, -2.7000,  0.1500, -2.3500,\n",
       "         2.9500, -1.7500,  3.9500, -3.0000, -0.4000, -0.5500,  2.2000, -0.1000,\n",
       "        -4.3000, -0.7000,  2.2500,  3.5500, -1.8500,  4.7000,  3.7000, -1.4000])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
